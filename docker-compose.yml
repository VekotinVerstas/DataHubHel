version: "2"

services:
  zookeeper:
    image: confluentinc/cp-zookeeper:5.3.0
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000

  kafka:
    image: confluentinc/cp-enterprise-kafka:5.3.0
    restart: always
    ports:
      - "127.0.0.1:29092:29092"
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: >-
        PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: >-
        PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_METRIC_REPORTERS: >-
        io.confluent.metrics.reporter.ConfluentMetricsReporter
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS: kafka:29092
      CONFLUENT_METRICS_REPORTER_ZOOKEEPER_CONNECT: zookeeper:2181
      CONFLUENT_METRICS_REPORTER_TOPIC_REPLICAS: 1
      CONFLUENT_METRICS_ENABLE: "true"
      CONFLUENT_SUPPORT_CUSTOMER_ID: "anonymous"

  datahubhel-db:
    image: kartoza/postgis
    environment:
      POSTGRES_USER: datahubhel
      POSTGRES_DBNAME: datahubhel
      POSTGRES_PASS: datahubhel
    volumes:
      - datahubhel-db-data:/var/lib/postgresql

  datahubhel:
    build: ./backend
    environment:
      DATABASE_URL: >-
        postgis://datahubhel:datahubhel@datahubhel-db/datahubhel
    ports:
      - "127.0.0.1:8000:8000"
    depends_on:
      - datahubhel-db
    volumes:
      - ./backend:/app
    stdin_open: true
    tty: true

  ksql-server:
    image: confluentinc/cp-ksql-server:5.3.0
    depends_on:
      - kafka
    ports:
      - "127.0.0.1:8088:8088"
    environment:
      KSQL_CONFIG_DIR: "/etc/ksql"
      KSQL_LOG4J_OPTS: >-
        -Dlog4j.configuration=file:/etc/ksql/log4j-rolling.properties
      KSQL_BOOTSTRAP_SERVERS: "kafka:9092"
      KSQL_HOST_NAME: ksql-server
      KSQL_APPLICATION_ID: "cp-all-in-one"
      KSQL_LISTENERS: "http://ksql-server:8088"
      KSQL_CACHE_MAX_BYTES_BUFFERING: 0
      KSQL_KSQL_SCHEMA_REGISTRY_URL: "http://schema-registry:8081"
      KSQL_PRODUCER_INTERCEPTOR_CLASSES: >-
        io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor
      KSQL_CONSUMER_INTERCEPTOR_CLASSES: >-
        io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor

  ksql-client:
    image: confluentinc/cp-ksql-cli:5.3.0
    depends_on:
      - ksql-server
    tty: true

  schema-registry:
    image: confluentinc/cp-schema-registry:5.3.0
    restart: always
    depends_on:
      - zookeeper
      - kafka
    ports:
      - "127.0.0.1:8081:8081"
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_CONNECTION_URL: zookeeper:2181

  kafka-sink-db:
    image: postgres:9.6.6-alpine
    environment:
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: noisedata
    volumes:
      - kafka-sink-db-data:/var/lib/postgresql/data

  kafka-connector:
    image: confluentinc/cp-kafka-connect:5.3.0
    restart: always
    depends_on:
      - schema-registry
      - kafka
      - zookeeper
    ports:
      - "127.0.0.1:8083:8083"
    environment:
      CONNECT_INTERNAL_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_INTERNAL_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_ZOOKEEPER_CONNECT: zookeeper:2181
      CONNECT_BOOTSTRAP_SERVERS: kafka:9092
      CONNECT_REST_ADVERTISED_HOST_NAME: kafka-connector
      CONNECT_GROUP_ID: compose-connect-group
      CONNECT_CONFIG_STORAGE_TOPIC: docker-connect-configs
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_OFFSET_STORAGE_TOPIC: docker-connect-offsets
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_STATUS_STORAGE_TOPIC: docker-connect-status
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8081
      CONNECT_KEY_CONVERTER: org.apache.kafka.connect.storage.StringConverter
      CONNECT_VALUE_CONVERTER: io.confluent.connect.avro.AvroConverter
      CONNECT_PLUGIN_PATH: /usr/share/java,/etc/kafka-connect/uber/,/etc/kafka-connect/plugins

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.3.0
    environment:
      node.name: elasticsearch
      cluster.name: docker-cluster
      bootstrap.memory_lock: "true"
      ES_JAVA_OPTS: "-Xms750m -Xmx750m"
      discovery.type: single-node
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - elasticsearch-data:/usr/share/elasticsearch/data
    ports:
      - "127.0.0.1:9200:9200"

  kibana:
    image: docker.elastic.co/kibana/kibana:7.3.0
    volumes:
      - ./kibana.yml:/usr/share/kibana/config/kibana.yml
    restart: always
    ports:
      - "127.0.0.1:5601:5601"
    depends_on:
      - elasticsearch

volumes:
  elasticsearch-data:
  kafka-sink-db-data:
  datahubhel-db-data:
